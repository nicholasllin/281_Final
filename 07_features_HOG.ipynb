{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from sklearn.manifold import TSNE\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "root = '.'\n",
    "data_folder = f'{root}/data'\n",
    "feature_data_folder = f'{root}/feature_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data):\n",
    "    \"\"\"\n",
    "    load 2D images and their labels\n",
    "\n",
    "    returns: \n",
    "    images (array): array of images as np arrays\n",
    "    labels (array): array of labels\n",
    "    \"\"\"\n",
    "    #create lists to store images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    #load webdataset\n",
    "    data = (wds.WebDataset(f'{path_to_data}', shardshuffle=True)\n",
    "            .decode(\"pil\").to_tuple(\"jpg\", \"json\"))\n",
    "    #iterate dataset\n",
    "    data_iter = iter(data)\n",
    "    #append dataset to lists\n",
    "    for row in data_iter:\n",
    "        image = np.array(row[0])\n",
    "        label = row[1]['label']\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    data.close()\n",
    "    return images, labels      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data(f'file:{data_folder}/train-000000.tar')\n",
    "val_images, val_labels = load_data(f'file:{data_folder}/val-000000.tar')\n",
    "test_images, test_labels = load_data(f'file:{data_folder}/test-000000.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of images:\", train_images.shape)\n",
    "print(\"Shape of labels:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "class_dict = dict(zip(unique, counts))\n",
    "#plot\n",
    "plt.bar(range(len(class_dict)), list(class_dict.values()), align='center')\n",
    "plt.xticks(range(len(class_dict)), list(class_dict.keys()), rotation = 'vertical')\n",
    "plt.title('Mars Images Class Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show example of 1 of each class\n",
    "label_names = ['crater', 'dark dune', 'slope streak', 'bright dune', 'impact ejecta', 'swiss cheese', 'spider']\n",
    "result = {}\n",
    "unique_values = np.unique(train_labels)\n",
    "for value in unique_values:\n",
    "    indices = np.where(train_labels==value)[0][:1]\n",
    "    result[value] = np.int_(indices)[0]\n",
    "print(result)\n",
    "#plotting first image for each class\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(result), figsize=(20,3))\n",
    "i = 0\n",
    "for key, value in result.items():\n",
    "    image = train_images[value]\n",
    "    label = label_names[key-1]\n",
    "    #label_name = label_names[label]\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_title(label)\n",
    "    axs[i].axis('off')\n",
    "    i += 1\n",
    "fig.suptitle('One Image For Each Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with 1 example for each class for visualization\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(result), figsize=(20,3))\n",
    "i = 0\n",
    "for key, value in result.items():\n",
    "    image = train_images[value]\n",
    "    label = label_names[key-1]\n",
    "    #testing gaussian blur\n",
    "    image = cv.GaussianBlur(image,(5,5),0)\n",
    "    #normalize\n",
    "    image = cv.normalize(image, None, 0, 1, cv.NORM_MINMAX, cv.CV_32F)\n",
    "    fd, hog_image = hog(image, orientations = 10, pixels_per_cell=(12,12),\n",
    "                        cells_per_block= (1,1), visualize = True, channel_axis=-1)\n",
    "    axs[i].imshow(hog_image)\n",
    "    axs[i].set_title(label)\n",
    "    axs[i].axis('off')\n",
    "    i += 1\n",
    "fig.suptitle('One HOG Image For Each Class')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply to all\n",
    "def extract_hog(img_dataset):\n",
    "    \"\"\" \n",
    "    Apply HOG feature extraction to all training images \n",
    "    args: img_dataset (training / testing dataset)\n",
    "\n",
    "    returns: train_images_hog (dataset of hog features)\n",
    "    \"\"\"\n",
    "    img_dataset_hog = []\n",
    "    for img in img_dataset:\n",
    "        fd, hog_image = hog(image, orientations = 8, pixels_per_cell=(16,16),\n",
    "                        cells_per_block= (1,1), visualize = True, channel_axis=-1)\n",
    "        \n",
    "        img_dataset_hog.append(hog_image.ravel()) #flatten\n",
    "\n",
    "    img_dataset_hog = np.array(img_dataset_hog)\n",
    "    return img_dataset_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_hog = extract_hog(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_hog = extract_hog(val_images)\n",
    "test_images_hog = extract_hog(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "np.save(f'{feature_data_folder}/train_images_hog', train_images_hog)\n",
    "np.save(f'{feature_data_folder}/val_images_hog', val_images_hog)\n",
    "np.save(f'{feature_data_folder}/test_images_hog', test_images_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_images_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne = TSNE(n_components = 2, random_state = 0)\n",
    "#X = tsne.fit_transform(train_images_hog)\n",
    "#y = [label_names[label_num] for label_num in train_labels]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
